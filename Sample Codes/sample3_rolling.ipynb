{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rolling Method \n",
    "Haoyang Han"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "get 35000 effective testing dataset.\n",
    "\n",
    "\n",
    "Total method used here should be：\n",
    "1. Standardization\n",
    "2. nan value transfermation\n",
    "3. feature selection via sharpe value\n",
    "4. rolling method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import bottleneck as bn\n",
    "\n",
    "# Define Hyperparameters\n",
    "T = 30\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# detailed keras function import\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "TSX[100042_7]\n",
      "<class 'str'>\n",
      "TSX[100038_3]\n",
      "<class 'str'>\n",
      "TSX[100042_4]\n",
      "<class 'str'>\n",
      "TSX[100010_2]\n",
      "<class 'str'>\n",
      "TSX[100038_4]\n",
      "<class 'str'>\n",
      "TSX[100042_3]\n",
      "<class 'str'>\n",
      "TSX[100010_1]\n",
      "<class 'str'>\n",
      "TSX[100042_2]\n",
      "<class 'str'>\n",
      "TSX[100042_1]\n",
      "<class 'str'>\n",
      "TSX[100002_1]\n",
      "<class 'str'>\n",
      "TSX[100036_1]\n",
      "<class 'str'>\n",
      "TSX[100012_1]\n",
      "<class 'str'>\n",
      "TSX[100029_1]\n",
      "<class 'str'>\n",
      "TSX[100009_1]\n",
      "<class 'str'>\n",
      "TSX[100029_2]\n",
      "<class 'str'>\n",
      "TSX[100038_2]\n",
      "<class 'str'>\n",
      "TSX[100042_5]\n",
      "<class 'str'>\n",
      "TSX[100018_1]\n",
      "<class 'str'>\n",
      "TSX[100038_1]\n",
      "<class 'str'>\n",
      "TSX[100042_6]\n"
     ]
    }
   ],
   "source": [
    "address = os.listdir(r'../factors_pickingtime')\n",
    "for path in address:\n",
    "    print(type(path))\n",
    "    print(path)\n",
    "add = ['TSX[100001_2]', 'TSX[100035_1]', 'TSX[100041_4]', 'TSX[100041_1]','TSX[100041_2]','TSX[100041_3]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "6_variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def import_dataset():\n",
    "    '''\n",
    "    read all 2-byte files and then concentrating them together. Follow this link:\n",
    "    https://blog.csdn.net/brucewong0516/article/details/79062340\n",
    "    \n",
    "    instead of using alpha as y,\n",
    "    we should use return rate as y.\n",
    "    '''\n",
    "    x = []\n",
    "    y = []\n",
    "    # import x\n",
    "    address = os.listdir(r'../factors_pickingtime')\n",
    "    u = 1\n",
    "    for path in address:\n",
    "        # if path in add:\n",
    "        parent = r'../factors_pickingtime'\n",
    "        abs_path = os.path.join(parent, path)\n",
    "        x_i = np.memmap(abs_path,dtype = np.float32, shape = (40000,1829))# ,shape = (204800, 1749))\n",
    "        x_i = np.asarray(x_i)\n",
    "        x_ = x_i[:,0:1082]\n",
    "        # x_ = x_i.reshape(-1,1)\n",
    "        print(np.shape(x_))\n",
    "        print(\"%d th factor have %d number of nan factors \"%(u, np.isnan(x_).sum()))\n",
    "        x.append(x_)\n",
    "        # print(abs_path)\n",
    "        u += 1\n",
    "    # import y\n",
    "    price = np.memmap('../quotes/stk_clsadj',dtype = np.float32, shape = (40000,1829))# ,shape = (204800, 1749))\n",
    "    \n",
    "    y = np.zeros((price.shape[0]-T,price.shape[1]))\n",
    "    '''\n",
    "    This is an iteration to create target y function;\n",
    "    Here we use Return rate minus Average Return Rate.\n",
    "\n",
    "    First we calculate the mean return rate for every single timeslot;\n",
    "    Then we calculate the return rate of each stock and return them back to y.\n",
    "\n",
    "    Here we used np.nanmean() function, in case some values would be nan.\n",
    "    '''\n",
    "    t0 = time.time()\n",
    "    for i in range(40000-T): \n",
    "        \n",
    "        for j in range(1082):\n",
    "            y[i,j-1] = np.log(price[i+T,j-1]/price[i,j-1])\n",
    "    t1 = time.time()\n",
    "    y = y[:,0:1082]\n",
    "    y_ = y.reshape(-1,1)\n",
    "    \n",
    "    # delete too-much nan value column\n",
    "    # x = np.delete(x, 5)\n",
    "    del address, x_i, x_, price, y\n",
    "    gc.collect()\n",
    "    print(\"y function running time should be, \", t1-t0)\n",
    "    print(\"the shape of x is:\", np.shape(x))\n",
    "    print(\"the shape of y is:\", y_.shape)\n",
    "    return x, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1082)\n",
      "1 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "2 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "3 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "4 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "5 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "6 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "7 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "8 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "9 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "10 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "11 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "12 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "13 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "14 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "15 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "16 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "17 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "18 th factor have 2075839 number of nan factors \n",
      "(40000, 1082)\n",
      "19 th factor have 0 number of nan factors \n",
      "(40000, 1082)\n",
      "20 th factor have 0 number of nan factors \n",
      "y function running time should be,  146.89887070655823\n",
      "the shape of x is: (20, 40000, 1082)\n",
      "the shape of y is: (43247540, 1)\n"
     ]
    }
   ],
   "source": [
    "x_, y_ = import_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline for possible solution:\n",
    "1. Standardization\n",
    "2. Develop Sharpe Ratio Criteria\n",
    "3. Select best Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(x):\n",
    "    '''\n",
    "    for every single factor, for every single time point, calculate prior 500 point's maximum and minimum, do standardization.\n",
    "    '''\n",
    "    \n",
    "    # window size(for standardization)\n",
    "    window = 500\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    x = np.delete(x, [0, 1, 17], axis = 0)\n",
    "    print('the shape of input matrix is %d, %d, %d' %(x.shape[0],x.shape[1], x.shape[2]))\n",
    "    print('This matrix have %d nan value' %(np.isnan(x).sum()))\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    x_bar = np.zeros((x.shape[0], (x.shape[1]-window), x.shape[2]))\n",
    "    for i in range(x.shape[0]):\n",
    "        print('%d th factor:'%i)\n",
    "        for j in range(x.shape[1]-window):\n",
    "            for k in range(x.shape[2]):\n",
    "                x_ = x[i, j:j+500, k].reshape((500, 1))\n",
    "                x_order = np.argsort(x_)\n",
    "                max_x = x_[x_order[10]]\n",
    "                min_x = x_[x_order[490]]\n",
    "                assert max_x >= min_x\n",
    "                if max_x - min_x != 0:\n",
    "                    x_bar[i,j,k] = (x[i,j+500,k] - min_x)/(max_x - min_x)\n",
    "                else:\n",
    "                    x_bar[i,j,k] = 0\n",
    "        gc.collect()\n",
    "        '''\n",
    "\n",
    "        for j in range(6):\n",
    "            x_ = x[i * 1082: i* 1082 + 1082, j]\n",
    "            x_order = np.argsort(x_)\n",
    "            if i == 0:\n",
    "                print(type(x_order))\n",
    "                print(x_[x_order[108]]) # here we use 108\n",
    "                print(x_[x_order[974]]) # here we use 1082 - 108 = 974 \n",
    "            max_x = x_[x_order[54]] #there exist nan value in this np array\n",
    "            min_x = x_[x_order[1028]]\n",
    "            if max_x - min_x != 0:\n",
    "                x_hat = (x_ - min_x)/(max_x - min_x) # this should be a range(0,1) standardization\n",
    "                x_hat = 2 * x_hat - 1\n",
    "                x_bar[i * 1082: i* 1082 + 1082, j] = x_hat\n",
    "            else:\n",
    "                x_hat = np.zeros(1082)\n",
    "                x_bar[i * 1082: i* 1082 + 1082, j] = x_hat\n",
    "        '''\n",
    "        \n",
    "    t1 = time.time()\n",
    "    print('Total transfer time is %d' %(t1-t0))\n",
    "    print(x_bar.shape)\n",
    "    x_bar = np.asarray(x_bar)\n",
    "    return x_bar\n",
    "\n",
    "\n",
    "# But we should notice here that we don't need nan transfer. Instead, we should delete those lines with nan value\n",
    "# No matter it's x or y.\n",
    "def nan_transfer(x):\n",
    "    where_are_nan = np.isnan(x)\n",
    "    where_are_inf = np.isinf(x)\n",
    "    x[where_are_nan] = 0\n",
    "    x[where_are_nan] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of input matrix is 17, 40000, 1082\n",
      "This matrix have 0 nan value\n",
      "0 th factor:\n",
      "1 th factor:\n",
      "2 th factor:\n",
      "3 th factor:\n",
      "4 th factor:\n",
      "5 th factor:\n",
      "6 th factor:\n",
      "7 th factor:\n",
      "8 th factor:\n",
      "9 th factor:\n",
      "10 th factor:\n",
      "11 th factor:\n",
      "12 th factor:\n",
      "13 th factor:\n",
      "14 th factor:\n",
      "15 th factor:\n",
      "16 th factor:\n",
      "Total transfer time is 6341\n",
      "(17, 39500, 1082)\n"
     ]
    }
   ],
   "source": [
    "x__ = standardization(x_)\n",
    "# x__ = nan_transfer(x__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_save = np.reshape(x__, [17,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../Data/x.csv', x_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../Data/y.csv', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_splitter(x, y):\n",
    "    '''\n",
    "    T = 30\n",
    "    training = 前19500\n",
    "    testing = 后19970\n",
    "    先截去后30个x\n",
    "    截去前500个y\n",
    "    再分\n",
    "    train_x: 0到1082*19500\n",
    "    train_y: 1082*500到1082*20000\n",
    "    test_x: 1082*19500到1082*39470\n",
    "    test_y: 1082*20000到1082*39970\n",
    "    \n",
    "    '''\n",
    "    # define hyper-parameter:\n",
    "    \n",
    "    \n",
    "    x = np.asarray(x)\n",
    "    # x = np.delete(x, [3, 8, 16], axis = 0)\n",
    "    y = np.asarray(y)\n",
    "    x = x.reshape(17,-1).T\n",
    "    y = y.reshape(-1,1)\n",
    "    '''  \n",
    "    # Cut first 30 rows of x\n",
    "    # 30 * 1082 = 32460\n",
    "    x = x[32460:,:]\n",
    "\n",
    "\n",
    "    # transfer nan to 0\n",
    "    x = np.nan_to_num(x)\n",
    "    y = np.nan_to_num(y)\n",
    "    '''\n",
    "    print(np.shape(x))\n",
    "    print(y.shape)\n",
    "    \n",
    "    # cutting first \n",
    "    train_X = x[:21099000,:]    # 3-D to 2-D\n",
    "    train_y = y[541000:21640000,:]\n",
    "    test_X = x[21099000:42706540,:]\n",
    "    test_y = y[21640000:43247540,:]\n",
    "    \n",
    "    \n",
    "    # deleting data if it have nan value inside of it.\n",
    "\n",
    "    # deleting rows form train dataset\n",
    "    train_index = []\n",
    "    for i in range(train_y.shape[0]):\n",
    "        if np.isnan(train_y[i]):\n",
    "            train_index.append(i)\n",
    "    train_X = np.delete(train_X, train_index, axis = 0)\n",
    "    train_y = np.delete(train_y, train_index, axis = 0)\n",
    "    \n",
    "    # deleting rows form test dataset\n",
    "    test_index = []\n",
    "    for i in range(test_y.shape[0]):\n",
    "        if np.isnan(test_y[i]):\n",
    "            test_index.append(i)\n",
    "    test_X = np.delete(test_X, test_index, axis = 0)\n",
    "    test_y = np.delete(test_y, test_index, axis = 0)\n",
    "\n",
    "    \n",
    "    '''\n",
    "    train_X= np.nan_to_num(train_X)\n",
    "    train_y= np.nan_to_num(train_y)\n",
    "    test_X= np.nan_to_num(test_X)\n",
    "    test_y= np.nan_to_num(test_y)\n",
    "    '''\n",
    "    print(\"The shape of training set's X is,\",train_X.shape)\n",
    "    print(\"The shape of training set's y is,\",train_y.shape)\n",
    "    print(\"The shape of testing set's X is,\",test_X.shape)\n",
    "    print(\"The shape of testing set's y is,\",test_y.shape)\n",
    "\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42739000, 17)\n",
      "(43247540, 1)\n",
      "The shape of training set's X is, (20106560, 17)\n",
      "The shape of training set's y is, (20106560, 1)\n",
      "The shape of testing set's X is, (21370430, 17)\n",
      "The shape of testing set's y is, (21370430, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = timing_splitter(x__, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_roll)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5117240, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_roll[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model_fittig\n",
    "\n",
    "\n",
    "Deep Learning Models Right Now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用的模型为：\n",
    "1. Simple MLP\n",
    "2. Ridge\n",
    "3. <font color = #ff0000> KNN </font>\n",
    "4. Lasso\n",
    "5. Bayesian\n",
    "6. <font color = #ff0000> MLP </font>\n",
    "7. Decision Tree\n",
    "8. Random Forest\n",
    "9. <font color = #ff0000> SGD </font>\n",
    "10. Gradient Boosting Decision Tree\n",
    "11. AdaBoost\n",
    "12. SVM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing for several judgement parameter\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score as acc_s\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "'''\n",
    "Since this is a regression problem instead of classification, \n",
    "we shouldn't use accuracy_score(compared one element from each other in this case .)\n",
    "Use MSE and RMSE criteria instead.\n",
    "\n",
    "'''\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mse(y_test, y_pred))\n",
    "\n",
    "def IC(x1, x2):\n",
    "    pearson = []\n",
    "    x1 = np.squeeze(x1)\n",
    "    x2 = np.squeeze(x2)\n",
    "    for i in range(int(np.shape(x1)[0]/1082)):\n",
    "        x1_ = x1[i*1082:i*1082+1082,]\n",
    "        x2_ = x2[i*1082:i*1082+1082,]\n",
    "        pearson_ = pearsonr(x1_, x2_)[0]\n",
    "        pearson.append(pearson_)\n",
    "    pearson = np.asarray(pearson)\n",
    "    pearson = np.squeeze(pearson)\n",
    "    '''\n",
    "    print(np.isnan(pearson).sum())\n",
    "    print(pearson.shape)\n",
    "    print(pearson.mean())\n",
    "    print(pearson.std())\n",
    "    '''\n",
    "    temp = pearson.mean()/pearson.std()\n",
    "    return temp\n",
    "\n",
    "def nan_transfor(x):\n",
    "    where_are_nan = np.isnan(x)\n",
    "    where_are_inf = np.isinf(x)\n",
    "    x[where_are_nan] = 0\n",
    "    x[where_are_nan] = 0\n",
    "    return x\n",
    "\n",
    "def predictor(func):\n",
    "    y_hat = func.predict(pred_x)\n",
    "    y_hat = y_hat.reshape(40000,-1)\n",
    "    return y_hat\n",
    "\n",
    "def fitting(func, x_roll = x_roll, y_roll = y_roll, x__ = x__):\n",
    "    '''\n",
    "    diivding the dataset into 8 parts. Use former part as training dataset and latter part as testint dataset.\n",
    "    '''\n",
    "    t0 = time.time()\n",
    "    print('model is %s' %func)\n",
    "    # define several returnable parameters\n",
    "    acc_1 = []    # mse\n",
    "    acc_2 = []    # rmse\n",
    "    acc_3 = []    # IC\n",
    "    length = 40000 *1082 / 8    \n",
    "    \n",
    "    assert np.shape(x_roll)[0] == np.shape(y_roll)[0] == 8\n",
    "\n",
    "    for i in range(np.shape(x_roll)[0]-1):\n",
    "        \n",
    "        train_X = np.asarray(x_roll[i])\n",
    "        test_X = np.asarray(x_roll[i+1])\n",
    "        train_y = np.asarray(y_roll[i])\n",
    "        test_y = np.asarray(y_roll[i+1])\n",
    "        print('%d th iteration'%i)\n",
    "        print(test_X.shape[1])\n",
    "        print(test_y.shape[0])\n",
    "        assert train_X.shape[1] == 17\n",
    "        assert train_X.shape[0] == train_y.shape[0]\n",
    "        assert test_X.shape[0] == test_y.shape[0]\n",
    "        \n",
    "        '''\n",
    "        我们的最终目标是返回一个40000*1082的matrix\n",
    "        我们需要一组完整的x， 一组去掉nan的x， 一组去掉nan的y。\n",
    "        去掉nan的x/y用来计算mse，rmse，IC index\n",
    "        不去掉的用来计算整体，方法是如果是第一个model就计算10000*1082，其他的计算5000*1082\n",
    "        '''\n",
    "        func.fit(train_X, train_y)\n",
    "        pred_y = func.predict(test_X)\n",
    "        if pred_y.ndim == 1:\n",
    "            pred_y = pred_y[:,np.newaxis]\n",
    "        assert np.shape(pred_y)[0] == np.shape(test_y)[0]\n",
    "        acc_1.append(mse(pred_y, test_y))\n",
    "        acc_2.append(rmse(pred_y, test_y))\n",
    "        acc_3.append(IC(pred_y, test_y))\n",
    "        \n",
    "        if i == 0:\n",
    "            output = func.predict(x__[:int(2*length),:])\n",
    "            if output.ndim == 1:\n",
    "                output = output[:,np.newaxis]\n",
    "            print('the %d th iteration. output shape is (%d,%d)' %(i, np.shape(output)[0], np.shape(output)[1]))\n",
    "        if i != 0:\n",
    "            output_ = func.predict(x__[int(length*(i+1)):int((i+2)*length),:])\n",
    "            if output_.ndim == 1:\n",
    "                output_ = output_[:,np.newaxis]\n",
    "            print('the %d th iteration. output shape is (%d,%d)' %(i, np.shape(output_)[0], np.shape(output_)[1]))\n",
    "            output = np.concatenate((output, output_))\n",
    "    \n",
    "    accuracy_1 = np.mean(acc_1)\n",
    "    accuracy_2 = np.mean(acc_2)\n",
    "    accuracy_3 = np.mean(acc_3)\n",
    "    output = output.reshape(40000,-1)\n",
    "    \n",
    "    print('average value of mse is %f' %(accuracy_1))\n",
    "    print('average value of rmse is %f' %(accuracy_2))\n",
    "    print('average value of IC is %f' %(accuracy_3))\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print('Total time used for fitting model %s is: %f'%(func,(t1-t0)))\n",
    "    \n",
    "    return output, accuracy_1, accuracy_2, accuracy_3, (t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Clear content of all memories\n",
    "'''\n",
    "Method = []\n",
    "MSE = []\n",
    "RMSE = []\n",
    "Time = []\n",
    "y_hat = []\n",
    "ic = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a very simple \n",
    "model1 = Sequential()\n",
    "model1.add(Dense(17, input_dim=17, kernel_initializer='normal', activation='sigmoid')) # relu will cause extra problem: loss = nan\n",
    "model1.add(Dense(6, kernel_initializer='normal', activation='linear'))\n",
    "model1.add(Dense(1, kernel_initializer='normal'))\n",
    "model1.compile(loss='mse', optimizer=SGD(lr = 2e-4, momentum = 0.9, nesterov = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20106560/20106560 [==============================] - 225s 11us/step - loss: 6.8838e-05\n",
      "Epoch 2/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 3/15\n",
      "20106560/20106560 [==============================] - 223s 11us/step - loss: 6.8817e-05\n",
      "Epoch 4/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 5/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 6/15\n",
      "20106560/20106560 [==============================] - 223s 11us/step - loss: 6.8817e-05\n",
      "Epoch 7/15\n",
      "20106560/20106560 [==============================] - 223s 11us/step - loss: 6.8817e-05\n",
      "Epoch 8/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 9/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 10/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 11/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 12/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 13/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 14/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n",
      "Epoch 15/15\n",
      "20106560/20106560 [==============================] - 224s 11us/step - loss: 6.8817e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1f8997f0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_X, train_y, epochs = 15, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a very simple \n",
    "model2 = Sequential()\n",
    "model2.add(Dense(17, input_dim=17, kernel_initializer='normal', activation='sigmoid')) # relu will cause extra problem: loss = nan\n",
    "model2.add(Dense(64, kernel_initializer='normal', activation='linear'))\n",
    "model2.add(Dense(32, kernel_initializer='normal', activation='linear'))\n",
    "model2.add(Dense(1, kernel_initializer='normal'))\n",
    "model2.compile(loss='mse', optimizer=SGD(lr = 2e-4, momentum = 0.9, nesterov = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20106560/20106560 [==============================] - 242s 12us/step - loss: 6.8817e-05\n",
      "Epoch 2/5\n",
      "20106560/20106560 [==============================] - 243s 12us/step - loss: 6.8817e-05\n",
      "Epoch 3/5\n",
      "20106560/20106560 [==============================] - 248s 12us/step - loss: 6.8817e-05\n",
      "Epoch 4/5\n",
      "20106560/20106560 [==============================] - 249s 12us/step - loss: 6.8817e-05\n",
      "Epoch 5/5\n",
      "20106560/20106560 [==============================] - 262s 13us/step - loss: 6.8817e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32bde198>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_X, train_y, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21370430/21370430 [==============================] - 107s 5us/step\n"
     ]
    }
   ],
   "source": [
    "score1 = model1.evaluate(test_X, test_y, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.511823561204402e-05"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21370430/21370430 [==============================] - 101s 5us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.612874424704367e-05"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = model2.evaluate(test_X, test_y, batch_size = 128)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.recurrent import SimpleRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a very simple \n",
    "model3 = Sequential()\n",
    "model3.add(SimpleRNN(32, activation = 'sigmoid', dropout = 0.1))\n",
    "model3.add(Dense(128, input_dim=17, kernel_initializer='normal', activation='sigmoid')) # relu will cause extra problem: loss = nan\n",
    "model3.add(Dense(64, kernel_initializer='normal', activation='linear'))\n",
    "model3.add(Dense(1, kernel_initializer='normal'))\n",
    "model3.compile(loss='mse', optimizer=SGD(lr = 2e-4, momentum = 0.9, nesterov = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer simple_rnn_1: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-88d59924f7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    956\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# to match the value shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer simple_rnn_1: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model3.fit(train_X, train_y, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is Ridge(alpha=0.6, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "0 th iteration\n",
      "17\n",
      "5117240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 2.558700581455999e-25 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0 th iteration. output shape is (10820000,1)\n",
      "1 th iteration\n",
      "17\n",
      "5185920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.88708247926861e-26 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 th iteration. output shape is (5410000,1)\n",
      "2 th iteration\n",
      "17\n",
      "5244720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.0976957659704557e-25 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 2 th iteration. output shape is (5410000,1)\n",
      "3 th iteration\n",
      "17\n",
      "5287280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 3.8699300847617513e-26 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 3 th iteration. output shape is (5410000,1)\n",
      "4 th iteration\n",
      "17\n",
      "5341120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.9231586721737939e-25 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 4 th iteration. output shape is (5410000,1)\n",
      "5 th iteration\n",
      "17\n",
      "5380160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.4155945094212022e-25 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 5 th iteration. output shape is (5410000,1)\n",
      "6 th iteration\n",
      "17\n",
      "5361870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:40: RuntimeWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number/precision: 1.612231505477241e-25 / 1.1102230246251565e-16\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 6 th iteration. output shape is (5410000,1)\n",
      "average value of mse is 0.000059\n",
      "average value of rmse is 0.007658\n",
      "average value of IC is 1.270726\n",
      "Total time used for fitting model Ridge(alpha=0.6, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) is: 36.988617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha = 0.6)\n",
    "y_hat_ridge, acc1, acc2, acc3, time_ = fitting(ridge)\n",
    "\n",
    "Method.append('Ridge')\n",
    "MSE.append(acc1)\n",
    "RMSE.append(acc2)\n",
    "ic.append(acc3)\n",
    "Time.append(time_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "0 th iteration\n",
      "17\n",
      "5117240\n",
      "the 0 th iteration. output shape is (10820000,1)\n",
      "1 th iteration\n",
      "17\n",
      "5185920\n",
      "the 1 th iteration. output shape is (5410000,1)\n",
      "2 th iteration\n",
      "17\n",
      "5244720\n",
      "the 2 th iteration. output shape is (5410000,1)\n",
      "3 th iteration\n",
      "17\n",
      "5287280\n",
      "the 3 th iteration. output shape is (5410000,1)\n",
      "4 th iteration\n",
      "17\n",
      "5341120\n",
      "the 4 th iteration. output shape is (5410000,1)\n",
      "5 th iteration\n",
      "17\n",
      "5380160\n",
      "the 5 th iteration. output shape is (5410000,1)\n",
      "6 th iteration\n",
      "17\n",
      "5361870\n",
      "the 6 th iteration. output shape is (5410000,1)\n",
      "average value of mse is 0.000059\n",
      "average value of rmse is 0.007668\n",
      "average value of IC is 0.128804\n",
      "Total time used for fitting model Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False) is: 45.484258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha = 0.1)\n",
    "\n",
    "y_hat_lasso, acc1, acc2, acc3, time_ = fitting(lasso)\n",
    "\n",
    "Method.append('Lasso')\n",
    "MSE.append(acc1)\n",
    "RMSE.append(acc2)\n",
    "ic.append(acc3)\n",
    "Time.append(time_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = {\n",
    "    'mse':np.asarray(MSE),\n",
    "    'rmse':np.asarray(RMSE),\n",
    "    'time':np.asarray(Time),\n",
    "    'IC':np.asarray(ic),\n",
    "    # 'y_hat':y_hat\n",
    "    # dataframe\n",
    "}\n",
    "result = pd.DataFrame(Dict, index = Method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking zeros for type\n",
    "zeros = np.zeros((40000, 747))\n",
    "y_hat_linear = np.c_[y_hat_linear, zeros]\n",
    "y_hat_ridge = np.c_[y_hat_ridge, zeros]\n",
    "y_hat_lasso = np.c_[y_hat_lasso, zeros]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking zeros for type\n",
    "zero = np.zeros((320, 1829))\n",
    "y_hat_linear = np.r_[y_hat_linear, zero]\n",
    "y_hat_ridge = np.r_[y_hat_ridge, zero]\n",
    "y_hat_lasso = np.r_[y_hat_lasso, zero]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer float64 into float32\n",
    "y_hat_linear = y_hat_linear.astype('float32')\n",
    "y_hat_ridge = y_hat_ridge.astype('float32')\n",
    "y_hat_lasso = y_hat_lasso.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output into requried type.\n",
    "# 288 k kb\n",
    "y_hat_linear.tofile('/opt/hhyang/6.29/rolling_linear/linear.bin')\n",
    "y_hat_ridge.tofile('/opt/hhyang/6.29/rolling_linear/ridge.bin')\n",
    "y_hat_lasso.tofile('/opt/hhyang/6.29/rolling_linear/lasso.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStatsTS(X, Y, quantile=10, window=500, minCnt=250):\n",
    "    \"\"\" \n",
    "    X: alpha\n",
    "    Y: forward returns\n",
    "    \"\"\"\n",
    "    #IC \n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    if X.shape != Y.shape:\n",
    "        raise\n",
    "    N = len(X)\n",
    "    IC = np.zeros((N,))\n",
    "\n",
    "    bottom = 1.0 / quantile\n",
    "    top = 1 - bottom\n",
    "\n",
    "    # ts rank\n",
    "    X = bn.move_rank(X, window=window, min_count=minCnt, axis=0)\n",
    "    # norm to [0, 1]\n",
    "    X = 0.5 * (X + 1)\n",
    "\n",
    "    # get common data\n",
    "    X = np.where((~np.isnan(X) & (~np.isnan(Y))), X, np.nan)\n",
    "    Y = np.where((~np.isnan(X) & (~np.isnan(Y))), Y, np.nan)\n",
    "    # cross-rank Y\n",
    "    Y_rk = bn.nanrankdata(Y, axis=1)\n",
    "    Y_rk /= bn.nanmax(Y_rk, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # ls\n",
    "    LS = np.nanmean(np.where(X > top, Y, np.nan), axis=1) \\\n",
    "         - np.nanmean(np.where(X < bottom, Y, np.nan), axis=1)\n",
    "\n",
    "    # Loop\n",
    "    for ii in range(N):\n",
    "        IC[ii] = np.corrcoef(X[ii][~np.isnan(X[ii])], Y_rk[ii][~np.isnan(Y_rk[ii])])[0,1]\n",
    "            \n",
    "        \n",
    "    return IC, LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39970, 1082)\n"
     ]
    }
   ],
   "source": [
    "Y_test = y_.reshape(-1, 1082)\n",
    "print(Y_test.shape)\n",
    "nans = np.nan*np.zeros((39970, 747))\n",
    "nan = np.nan*np.zeros((350, 1829))\n",
    "Y_test = np.c_[Y_test, nans]\n",
    "Y_test = np.r_[Y_test, nan]\n",
    "Y_test = Y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in greater\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: Mean of empty slice\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in less\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3175: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3109: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  c *= 1. / np.float64(fact)\n",
      "/Users/kevin/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:3109: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= 1. / np.float64(fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([nan, nan, nan, ..., nan, nan, nan]),\n",
       " array([nan, nan, nan, ..., nan, nan, nan], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getStatsTS(y_hat_linear, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(5):\n",
    "        if k == 0:\n",
    "        \n",
    "        elif k != 0:\n",
    "            \n",
    "        k += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
